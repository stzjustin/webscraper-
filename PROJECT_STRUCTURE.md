# ğŸ“ Projekt-Struktur - Web Scraper Pro

## Ãœbersicht aller Dateien

```
webscraper-/
â”‚
â”œâ”€â”€ ğŸ“„ web_scraper_pro.py          # â­ HAUPT-SCRAPER (NEU & VERBESSERT)
â”‚   â””â”€â”€ Professioneller Web-Scraper mit:
â”‚       - Intelligenter Keyword-Extraktion
â”‚       - Batch-Processing
â”‚       - Retry-Logik
â”‚       - Progress Bars
â”‚       - Strukturiertes Logging
â”‚
â”œâ”€â”€ ğŸ“„ scraper.py                  # Original-Scraper (einfache Version)
â”‚   â””â”€â”€ Nur fÃ¼r einzelne URLs, keine Crawling-Funktion
â”‚
â”œâ”€â”€ ğŸ“‹ requirements-pro.txt        # â­ Dependencies fÃ¼r PRO-Version
â”‚   â””â”€â”€ Alle benÃ¶tigten Python-Pakete
â”‚
â”œâ”€â”€ ğŸ“‹ requirements.txt            # Dependencies fÃ¼r Original-Scraper
â”‚
â”œâ”€â”€ âš™ï¸  web_scraper_pro.spec       # PyInstaller Konfiguration
â”‚   â””â”€â”€ FÃ¼r Erstellung von ausfÃ¼hrbaren Dateien
â”‚
â”œâ”€â”€ ğŸ”¨ build_mac.sh                # â­ Build-Skript fÃ¼r macOS
â”‚   â””â”€â”€ Erstellt Standalone-App fÃ¼r Mac (Intel & Silicon)
â”‚
â”œâ”€â”€ ğŸ”¨ build_windows.bat           # Build-Skript fÃ¼r Windows
â”‚   â””â”€â”€ Erstellt .exe fÃ¼r Windows
â”‚
â”œâ”€â”€ ğŸ”¨ build_linux.sh              # Build-Skript fÃ¼r Linux
â”‚   â””â”€â”€ Erstellt Executable fÃ¼r Linux
â”‚
â”œâ”€â”€ ğŸš€ quickstart_mac.sh           # â­ SCHNELLSTART fÃ¼r Mac
â”‚   â””â”€â”€ One-Click Setup & Run
â”‚
â”œâ”€â”€ âš™ï¸  config_example.yaml        # Beispiel-Konfiguration
â”‚   â””â”€â”€ Umbenennen zu config.yaml zum Nutzen
â”‚
â”œâ”€â”€ ğŸ“– README_PRO.md               # â­ AUSFÃœHRLICHE ANLEITUNG
â”‚   â””â”€â”€ Komplette Dokumentation mit:
â”‚       - Schritt-fÃ¼r-Schritt-Anleitungen
â”‚       - Installation fÃ¼r alle Plattformen
â”‚       - n8n Integration
â”‚       - Troubleshooting
â”‚       - FAQ
â”‚
â”œâ”€â”€ ğŸ“– QUICKSTART.md               # â­ 5-MINUTEN SCHNELLSTART
â”‚   â””â”€â”€ Speziell fÃ¼r Mac Silicon Chip
â”‚
â”œâ”€â”€ ğŸ“– PROJECT_STRUCTURE.md        # Diese Datei
â”‚   â””â”€â”€ Ãœbersicht der Projekt-Struktur
â”‚
â”œâ”€â”€ ğŸ“– README.md                   # Original-README
â”‚   â””â”€â”€ FÃ¼r einfachen scraper.py
â”‚
â””â”€â”€ ğŸ“„ example.py                  # Beispiel-Code
    â””â”€â”€ Zeigt wie man scraper.py nutzt
```

---

## ğŸ¯ Welche Datei brauchst du?

### Als AnfÃ¤nger (Mac Silicon):
â¡ï¸ **Start:** `QUICKSTART.md`
â¡ï¸ **AusfÃ¼hren:** `./quickstart_mac.sh`

### FÃ¼r andere Plattformen:
â¡ï¸ **Anleitung:** `README_PRO.md` (Abschnitt "Detaillierte Installation")

### Executable erstellen:
â¡ï¸ **Mac:** `./build_mac.sh`
â¡ï¸ **Windows:** `build_windows.bat`
â¡ï¸ **Linux:** `./build_linux.sh`

### Code anpassen:
â¡ï¸ **Haupt-Code:** `web_scraper_pro.py`
â¡ï¸ **Build-Config:** `web_scraper_pro.spec`
â¡ï¸ **Einstellungen:** `config_example.yaml` â†’ `config.yaml`

### Hilfe & Support:
â¡ï¸ **Alles:** `README_PRO.md`
â¡ï¸ **Schnell:** `QUICKSTART.md`
â¡ï¸ **FAQ:** `README_PRO.md` (Abschnitt "FAQ")

---

## ğŸ”„ Workflow-Ãœbersicht

### 1ï¸âƒ£ Entwicklung (Python)

```bash
# Setup
python3 -m venv venv
source venv/bin/activate
pip install -r requirements-pro.txt

# Scraper ausfÃ¼hren
python web_scraper_pro.py

# Anpassen
vim web_scraper_pro.py
vim config.yaml
```

### 2ï¸âƒ£ Build (Executable)

```bash
# Mac
./build_mac.sh
â†’ dist/WebScraperPro

# Windows
build_windows.bat
â†’ dist\WebScraperPro.exe

# Linux
./build_linux.sh
â†’ dist/WebScraperPro
```

### 3ï¸âƒ£ Distribution

**Mac:**
```bash
# Als App Bundle
sudo cp -r dist/WebScraperPro.app /Applications/

# Als Binary
cp dist/WebScraperPro /usr/local/bin/
```

**Windows:**
- Kopiere `dist/` Ordner zu jedem Windows-PC
- Doppelklick auf `WebScraperPro.exe`

**Linux:**
```bash
sudo cp dist/WebScraperPro /usr/local/bin/
sudo chmod +x /usr/local/bin/WebScraperPro
```

---

## ğŸ“¦ Output-Struktur

Nach dem Scraping:

```
~/Desktop/WebScraperPDFs/
â”‚
â”œâ”€â”€ ğŸ“„ 001_20250107_143052_homepage_features_example_com.pdf
â”œâ”€â”€ ğŸ“„ 002_20250107_143055_pricing_plans_example_com.pdf
â”œâ”€â”€ ğŸ“„ 003_20250107_143058_contact_support_example_com.pdf
â”œâ”€â”€ ...
â”‚
â”œâ”€â”€ ğŸ“‹ scraped_urls.json           # Alle gefundenen URLs
â”‚   â””â”€â”€ {
â”‚       "start_url": "https://example.com",
â”‚       "timestamp": "2025-01-07T14:30:50",
â”‚       "total_urls": 50,
â”‚       "urls": [...]
â”‚   }
â”‚
â””â”€â”€ ğŸ“‹ scraper_20250107_143050.log # Log-Datei
    â””â”€â”€ Alle Events, Fehler, Warnungen
```

---

## ğŸ›  Development

### Code-Struktur (`web_scraper_pro.py`)

```python
# 1. CONFIGURATION
ScraperConfig           # Dataclass fÃ¼r alle Settings

# 2. LOGGING
ColoredFormatter        # Farbiges Terminal-Logging
setup_logging()         # Logger-Konfiguration

# 3. KEYWORD EXTRACTION
KeywordExtractor        # YAKE-basierte Keyword-Extraktion
â”œâ”€â”€ extract()           # Haupt-Methode
â”œâ”€â”€ _clean_keyword()    # Keyword-Bereinigung
â””â”€â”€ _extract_frequent_words()  # Fallback-Methode

# 4. PDF GENERATION
PDFGenerator            # ReportLab PDF-Erstellung
â”œâ”€â”€ create_pdf()        # Haupt-PDF-Erstellung
â”œâ”€â”€ _generate_filename()  # Intelligente Benennung
â””â”€â”€ _escape_xml()       # XML-Escaping fÃ¼r ReportLab

# 5. WEB SCRAPING
WebScraper              # Haupt-Scraper-Klasse
â”œâ”€â”€ setup_driver()      # Chrome/Selenium Setup
â”œâ”€â”€ fetch_page()        # Page-Load mit Retry
â”œâ”€â”€ normalize_url()     # URL-Normalisierung
â”œâ”€â”€ extract_links()     # Link-Extraktion
â”œâ”€â”€ extract_text()      # Text-Bereinigung
â”œâ”€â”€ crawl()             # Website-Crawling
â”œâ”€â”€ create_pdfs()       # PDF-Batch-Processing
â””â”€â”€ run()               # Haupt-Workflow

# 6. USER INPUT
get_user_input()        # Interaktive URL/Page-Input

# 7. MAIN
main()                  # Entry Point
```

### AnpassungsmÃ¶glichkeiten

#### PDF-Layout Ã¤ndern
```python
# In PDFGenerator._setup_styles()
self.body_style = ParagraphStyle(
    'CustomBody',
    fontSize=12,  # GrÃ¶ÃŸer
    textColor=HexColor('#000000'),  # Schwarz
    ...
)
```

#### Keywords anpassen
```python
# In ScraperConfig
num_keywords: int = 5  # Statt 3
keyword_max_ngram: int = 3  # Statt 2 (lÃ¤ngere Phrasen)
```

#### Delay Ã¤ndern
```python
# In ScraperConfig
delay_between_requests: float = 1.0  # Schneller (âš ï¸ riskant!)
```

#### Ignore-Patterns erweitern
```python
# In ScraperConfig
ignore_patterns: List[str] = [
    "login", "logout", ...,
    "mypattern",  # Dein Pattern
]
```

---

## ğŸ§ª Testing

```bash
# Unit-Tests (TODO)
pytest tests/

# Manueller Test mit kleiner Site
python web_scraper_pro.py
# URL: https://example.com
# Max: 5
```

---

## ğŸš€ Deployment

### Docker (Optional)

```dockerfile
FROM python:3.11-slim

# Install Chrome
RUN apt-get update && apt-get install -y \
    chromium chromium-driver

WORKDIR /app
COPY requirements-pro.txt .
RUN pip install -r requirements-pro.txt

COPY web_scraper_pro.py .

ENTRYPOINT ["python", "web_scraper_pro.py"]
```

### n8n Integration

Siehe `README_PRO.md` Abschnitt "n8n Integration"

---

## ğŸ“Š Features Comparison

| Feature | scraper.py | web_scraper_pro.py |
|---------|------------|---------------------|
| **Einzelne URL** | âœ… | âœ… |
| **VollstÃ¤ndiges Crawling** | âŒ | âœ… |
| **Keyword-Extraktion** | âŒ | âœ… |
| **Intelligente Benennung** | âŒ | âœ… |
| **Batch-Processing** | âŒ | âœ… |
| **Retry-Logik** | âŒ | âœ… |
| **Progress Bars** | âŒ | âœ… |
| **Strukturiertes Logging** | âŒ | âœ… |
| **Konfigurierbar** | âŒ | âœ… |
| **Memory-Optimierung** | âŒ | âœ… |
| **n8n-optimiert** | âš ï¸ | âœ… |

â¡ï¸ **Empfehlung:** Verwende `web_scraper_pro.py`!

---

## ğŸ“ TODO / Roadmap

- [ ] GUI-Version (Electron/Tkinter)
- [ ] Login-Support fÃ¼r geschÃ¼tzte Seiten
- [ ] Sitemap.xml Parsing
- [ ] Paralleles Crawling (Multi-Threading)
- [ ] Cloud-Storage Integration (S3, Azure)
- [ ] REST API Wrapper
- [ ] Docker Image
- [ ] Unit Tests
- [ ] CI/CD Pipeline

---

## ğŸ¤ Contributing

Pull Requests willkommen!

**Setup:**
```bash
git clone https://github.com/your-repo/webscraper-.git
cd webscraper-
python3 -m venv venv
source venv/bin/activate
pip install -r requirements-pro.txt
pip install black flake8 pytest mypy
```

**Code-Style:**
```bash
# Format
black web_scraper_pro.py

# Lint
flake8 web_scraper_pro.py

# Type-Check
mypy web_scraper_pro.py
```

---

## ğŸ“œ License

MIT License - Siehe `LICENSE`

---

**Version:** 2.0
**Last Updated:** 2025-01-07
**Author:** Web Scraper Pro Team
